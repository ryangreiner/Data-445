{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6c1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. c) LOOCV\n",
    "# 2. c) high bias low variance\n",
    "# 3. b) low bias high variance\n",
    "# 4. Regularization reduces variance by shrinking some of the parameters to almost 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41d0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'ryan-greiner-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the file to be read from s3 bucket\n",
    "file_key = 'framingham.csv'\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading CSV file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80c678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1-score of model 1 is 0.7626333183261893\n",
      "The F1-score of model 2 is 0.7676995082072852\n"
     ]
    }
   ],
   "source": [
    "heart = heart.dropna()\n",
    "\n",
    "X1 = heart[['age', 'currentSmoker', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']]\n",
    "X2 = heart[['age', 'currentSmoker', 'totChol', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "F1 = list()\n",
    "F2 = list()\n",
    "kfold = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X1):\n",
    "    X1_train, X1_val = X1.iloc[train_idx], X1.iloc[test_idx]\n",
    "    X2_train, X2_val = X2.iloc[train_idx], X2.iloc[test_idx]\n",
    "    Y_train, Y_val = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X1_train = scaler.fit_transform(X1_train)\n",
    "    X1_val = scaler.fit_transform(X1_val)\n",
    "    X2_train = scaler.fit_transform(X2_train)\n",
    "    X2_val = scaler.fit_transform(X2_val)\n",
    "    \n",
    "    logit_md1 = LogisticRegression().fit(X1_train, Y_train)\n",
    "    logit_md2 = LogisticRegression().fit(X2_train, Y_train)\n",
    "    \n",
    "    logit_pred1 = logit_md1.predict_proba(X1_val)[:, 1]\n",
    "    logit_pred2 = logit_md2.predict_proba(X2_val)[:, 1]\n",
    "    \n",
    "    logit_label1 = np.where(logit_pred1 < .25, 0, 1)\n",
    "    logit_label2 = np.where(logit_pred2 < .25, 0, 1)\n",
    "     \n",
    "    F1.append(f1_score(Y_val, logit_label1, average='weighted'))\n",
    "    F2.append(f1_score(Y_val, logit_label2, average='weighted'))\n",
    "\n",
    "F_score1 = np.mean(F1)\n",
    "F_score2 = np.mean(F2)\n",
    "\n",
    "print('The F1-score of model 1 is', F_score1)\n",
    "print('The F1-score of model 2 is', F_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first model gave a higher F-score so it is the better model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
